# -*- coding: utf-8 -*-
"""Aplicações da Ciência de Dados em Tecnologias Disruptivas - Módulo 13

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dkL-x4KvE7XkSzlf3VNdkAUPePF4WCXL

Optical Flow Sparse no Google Colab
"""

# Célula 1: Importando bibliotecas e carregando o vídeo
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Carregar um vídeo da biblioteca do Colab
video_path = 'https://github.com/opencv/opencv/blob/master/samples/data/vtest.avi?raw=true'
cap = cv2.VideoCapture(video_path)

# Definindo parâmetros para detectar pontos de interesse
feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Lendo o primeiro quadro
ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)

# Detectando pontos de interesse
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

# Célula 2: Calculando o Optical Flow
lk_params = dict(winSize=(15, 15), maxLevel=2,
                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Criando uma máscara para desenhar as trajetórias
mask = np.zeros_like(old_frame)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculando o fluxo óptico
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Selecionando pontos bons
    good_new = p1[st == 1]
    good_old = p0[st == 1]

    # Desenhando os pontos e suas trajetórias
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel().astype(int)  # Convertendo para inteiro
        c, d = old.ravel().astype(int)   # Convertendo para inteiro
        mask = cv2.line(mask, (a, b), (c, d), (0, 255, 0), 2)
        frame = cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)

    img = cv2.add(frame, mask)
    cv2_imshow(img)

    # Atualizando quadros e pontos
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)

cap.release()
cv2.destroyAllWindows()

"""Testar Aplicações do Optical Flow Sparse"""

# Célula 1: Importando bibliotecas e carregando o vídeo
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Carregar um vídeo de exemplo
video_path = 'https://github.com/opencv/opencv/blob/master/samples/data/vtest.avi?raw=true'
cap = cv2.VideoCapture(video_path)

# Definindo parâmetros para detectar pontos de interesse
feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Lendo o primeiro quadro
ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)

# Detectando pontos de interesse
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

# Célula 2: Calculando o Optical Flow
lk_params = dict(winSize=(15, 15), maxLevel=2,
                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Criando uma máscara para desenhar as trajetórias
mask = np.zeros_like(old_frame)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculando o fluxo óptico
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Selecionando pontos bons
    good_new = p1[st == 1]
    good_old = p0[st == 1]

    # Desenhando os pontos e suas trajetórias
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel().astype(int)  # Convertendo para inteiro
        c, d = old.ravel().astype(int)   # Convertendo para inteiro
        mask = cv2.line(mask, (a, b), (c, d), (0, 255, 0), 2)
        frame = cv2.circle(frame, (a, b), 5, (0, 0, 255), -1)

    img = cv2.add(frame, mask)
    cv2_imshow(img)

    # Atualizando quadros e pontos
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)

cap.release()
cv2.destroyAllWindows()

# Célula 3: Analisando os resultados
import matplotlib.pyplot as plt

# Lista para armazenar o número de pontos rastreados em cada quadro
tracked_points = []

# Reiniciando a leitura do vídeo
cap = cv2.VideoCapture(video_path)

# Lendo o primeiro quadro novamente
ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)

# Detectando pontos de interesse
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculando o fluxo óptico
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Selecionando pontos bons
    good_new = p1[st == 1]
    good_old = p0[st == 1]

    # Armazenando o número de pontos rastreados
    tracked_points.append(len(good_new))

    # Atualizando quadros e pontos
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)

cap.release()

# Gerando o gráfico
plt.figure(figsize=(12, 6))
plt.plot(tracked_points, marker='o')
plt.title('Número de Pontos Rastreado ao Longo do Tempo')
plt.xlabel('Quadros')
plt.ylabel('Número de Pontos Rastreado')
plt.grid()
plt.show()