# -*- coding: utf-8 -*-
"""Aplicações da Ciência de Dados em Tecnologias Disruptivas - Módulo 12

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xwxc7Ijf9s-v0Yf2rUNJwgx3ZCI89BrO

CAMShift no Google Colab
"""

# Instalação da biblioteca OpenCV
!pip install opencv-python

# Importação das bibliotecas necessárias
import cv2
import numpy as np
from google.colab import files
from google.colab.patches import cv2_imshow

# Função para fazer o upload do vídeo
uploaded = files.upload()
video_filename = list(uploaded.keys())[0]  # Obtendo o nome do arquivo enviado

# Carregar o vídeo enviado pelo usuário
cap = cv2.VideoCapture(video_filename)
# Verifica se o vídeo foi carregado corretamente
if not cap.isOpened():
    print("Erro ao abrir o vídeo.")
else:
    # Captura o primeiro quadro para definir a ROI
    ret, frame = cap.read()
    if ret:
        # Exibir o primeiro quadro
        cv2_imshow(frame)
        # Converter o quadro para o espaço de cores HSV
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        # Definindo a faixa de cor para a detecção (verde como exemplo)
        lower_green = np.array([40, 40, 40])
        upper_green = np.array([80, 255, 255])
        # Criar uma máscara para detectar a cor verde
        mask = cv2.inRange(hsv, lower_green, upper_green)
        # Encontrar contornos na máscara
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        # Se encontrar contornos, defina a ROI com base no maior contorno
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(largest_contour)
            roi = (x, y, w, h)
            roi_hist = cv2.calcHist([frame[y:y+h, x:x+w]], [0, 1], None, [256, 256], [0, 180, 0, 256])
            cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)
        else:
            print("Nenhum contorno encontrado. A ROI não foi definida.")
            cap.release()
            exit()
    else:
        print("Erro ao ler o primeiro quadro do vídeo.")

# Lista para armazenar os quadros resultantes
output_frames = []

# Loop para rastrear o objeto no vídeo
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Converter para espaço de cores HSV
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Calcular a probabilidade da nova posição
    back_project = cv2.calcBackProject([hsv], [0, 1], roi_hist, [0, 180, 0, 256], 1)

    # Aplicar CAMShift
    ret_val = cv2.CamShift(back_project, roi, (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1))

    # Desconstruir o retorno do CamShift
    if ret_val is not None:
        # O retorno é uma tupla contendo a caixa de rastreamento e a nova ROI
        rotated_rect, track_window = ret_val

        # Desenhar a caixa de rastreamento
        pts = cv2.boxPoints(rotated_rect)  # Usar a RotatedRect diretamente
        pts = np.int0(pts)
        cv2.polylines(frame, [pts], True, (255, 0, 0), 2)

    # Adicionar o quadro resultante à lista
    output_frames.append(frame)

# Liberar o vídeo
cap.release()

# Exibir todos os quadros resultantes no final
for output_frame in output_frames:
    cv2_imshow(output_frame)

"""Avaliar Comparativamente o CAMShift com Meanshift"""

import cv2
import numpy as np
from google.colab import files
from IPython.display import clear_output

# Realizar o upload do vídeo
uploaded = files.upload()
clear_output()  # Limpa a saída para uma interface mais limpa

# Acessar o nome do arquivo de vídeo enviado
video_path = next(iter(uploaded.keys()))

# Capturar o vídeo carregado
cap = cv2.VideoCapture(video_path)

# Ler o primeiro quadro e definir a região de interesse (ROI)
ret, frame = cap.read()
x, y, w, h = 300, 200, 100, 50  # Coordenadas iniciais da ROI
roi = frame[y:y+h, x:x+w]
hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
roi_hist = cv2.calcHist([hsv_roi], [0, 1], None, [180, 256], [0, 180, 0, 256])
cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)

# Função para aplicar o CAMShift
def aplicar_camshift(cap, roi_hist):
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    output_camshift = []
    x, y, w, h = 300, 200, 100, 50
    frame_count = 0  # Contador de quadros para amostrar

    while True:
        ret, frame = cap.read()
        if not ret or frame_count > 100:  # Limitar a 100 quadros
            break
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        back_project = cv2.calcBackProject([hsv], [0, 1], roi_hist, [0, 180, 0, 256], 1)
        ret_val = cv2.CamShift(back_project, (x, y, w, h), (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1))

        if ret_val is not None:
            rotated_rect, (x, y, w, h) = ret_val
            pts = cv2.boxPoints(rotated_rect)
            pts = np.int0(pts)
            cv2.polylines(frame, [pts], True, (0, 0, 255), 2)

        # Apenas adicionar um de cada 10 quadros processados
        if frame_count % 10 == 0:
            output_camshift.append(frame)

        frame_count += 1

    return output_camshift

# Função para aplicar o Meanshift
def aplicar_meanshift(cap, roi_hist):
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    output_meanshift = []
    x, y, w, h = 300, 200, 100, 50
    frame_count = 0  # Contador de quadros para amostrar

    while True:
        ret, frame = cap.read()
        if not ret or frame_count > 100:  # Limitar a 100 quadros
            break
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        back_project = cv2.calcBackProject([hsv], [0, 1], roi_hist, [0, 180, 0, 256], 1)
        _, (x, y, w, h) = cv2.meanShift(back_project, (x, y, w, h), (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1))
        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)

        # Apenas adicionar um de cada 10 quadros processados
        if frame_count % 10 == 0:
            output_meanshift.append(frame)

        frame_count += 1

    return output_meanshift

# Executar ambos os métodos e armazenar os quadros resultantes
output_camshift = aplicar_camshift(cap, roi_hist)
output_meanshift = aplicar_meanshift(cap, roi_hist)

# Liberar o vídeo
cap.release()

# Exibir os resultados para comparação
print("Resultados do CAMShift:")
for frame in output_camshift:
    cv2_imshow(frame)

print("Resultados do Meanshift:")
for frame in output_meanshift:
    cv2_imshow(frame)